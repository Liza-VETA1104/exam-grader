import pandas as pd
import numpy as np
import re
import joblib
from scipy.sparse import hstack, csr_matrix
import streamlit as st
import tempfile
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞", page_icon="üìù", layout="wide")
st.title("üìù –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—Ü–µ–Ω–∫–∞ —É—Å—Ç–Ω–æ–≥–æ —ç–∫–∑–∞–º–µ–Ω–∞ –ø–æ —Ä—É—Å—Å–∫–æ–º—É —è–∑—ã–∫—É")
st.write("–ó–∞–≥—Ä—É–∑–∏ CSV —Ñ–∞–π–ª —Å —ç–∫–∑–∞–º–µ–Ω–∞—Ü–∏–æ–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –∏ –ø–æ–ª—É—á–∏ –æ—Ü–µ–Ω–∫–∏")

# === –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π ===
@st.cache_resource
def load_models():
    try:
        tfidf = joblib.load('tfidf_vectorizer.pkl')
        scaler = joblib.load('feature_scaler.pkl')
        model_q1 = joblib.load('model_q1.pkl')
        model_q2 = joblib.load('model_q2.pkl')
        model_q3 = joblib.load('model_q3.pkl')
        model_q4 = joblib.load('model_q4_enhanced.pkl')
        tfidf_q4 = joblib.load('tfidf_q4.pkl')
        scaler_q4 = joblib.load('scaler_q4.pkl')
        return tfidf, scaler, model_q1, model_q2, model_q3, model_q4, tfidf_q4, scaler_q4
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return None

# –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–µ–π
with st.spinner('–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª–∏...'):
    models = load_models()

if models is None:
    st.stop()

tfidf, scaler, model_q1, model_q2, model_q3, model_q4, tfidf_q4, scaler_q4 = models
st.success("‚úÖ –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")

# === –§—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ (—Ç–≤–æ–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏) ===
def clean_html(text):
    clean = re.compile('<.*?>')
    return re.sub(clean, ' ', str(text)).replace('  ', ' ').strip()

def remove_instruction(transcript, q_num):
    if q_num == 1: start_phrase = "–ù–∞—á–∏–Ω–∞–π—Ç–µ —Å–≤–æ–π –¥–∏–∞–ª–æ–≥."
    elif q_num == 2: start_phrase = "–û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–±–µ—Å–µ–¥–Ω–∏–∫–∞ –ø–æ–ª–Ω—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏."
    elif q_num == 3: start_phrase = "–ü–æ–±–ª–∞–≥–æ–¥–∞—Ä–∏—Ç–µ –∑–∞ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é."
    elif q_num == 4: start_phrase = "–ö–æ–≥–¥–∞ –±—É–¥–µ—Ç–µ –≥–æ—Ç–æ–≤—ã, –º–æ–∂–µ—Ç–µ –Ω–∞—á–∏–Ω–∞—Ç—å –æ–ø–∏—Å—ã–≤–∞—Ç—å."
    else: return transcript
    idx = transcript.find(start_phrase)
    return transcript[idx + len(start_phrase):].strip() if idx != -1 else transcript

def extract_features(text):
    sentences = re.split(r'[.!?]+', text)
    n_sents = len([s for s in sentences if len(s.strip()) > 0])
    words = text.split()
    n_words = len(words)
    avg_sent_len = n_words / n_sents if n_sents > 0 else 0
    return [n_sents, n_words, avg_sent_len, int('?' in text)]

def get_q4_features_enhanced(text):
    text_low = text.lower()
    return {
        'has_season': int(any(w in text_low for w in ['–ª–µ—Ç–æ', '–∑–∏–º–∞', '–≤–µ—Å–Ω–∞', '–æ—Å–µ–Ω—å', '—Ç—ë–ø–ª–æ–µ –≤—Ä–µ–º—è', '—Å–Ω–µ–≥', '–¥–æ–∂–¥—å'])),
        'has_place': int(any(w in text_low for w in ['–∫—É—Ö–Ω—è', '–¥–æ–º', '–ø–∞—Ä–∫', '–≤–æ–∫–∑–∞–ª', '—Ä–µ–∫–∞', '—É–ª–∏—Ü–∞'])),
        'has_people_count': int(any(w in text_low for w in ['–æ–¥–∏–Ω', '–¥–≤–∞', '—Ç—Ä–∏', '—á–µ—Ç—ã—Ä–µ', '–º–Ω–æ–≥–æ –¥–µ—Ç–µ–π', '—Ü–µ–ª–∞—è —Å–µ–º—å—è'])),
        'has_family': int(any(w in text_low for w in ['–≤ –Ω–∞—à–µ–π —Å–µ–º—å–µ', '—É –º–µ–Ω—è —Ç—Ä–æ–µ –¥–µ—Ç–µ–π', '—è —Å—Ç–∞—Ä—à–∞—è', '–º–æ–π –±—Ä–∞—Ç'])),
        'has_hobby': int(any(w in text_low for w in ['–ª—é–±–ª—é –≥–æ—Ç–æ–≤–∏—Ç—å', '–∏–≥—Ä–∞—é –≤ —Ñ—É—Ç–±–æ–ª', '–≥—É–ª—è—é –Ω–∞ –ø—Ä–∏—Ä–æ–¥–µ', '–≤—ã—à–∏–≤–∞—é'])),
        'n_sentences': len(re.split(r'[.!?]+', text)),
        'is_structured': int(len(re.findall(r'\b(–Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ|–∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ|—è –≤–∏–∂—É|—Ä–∞—Å—Å–∫–∞–∂—É –æ)\b', text_low)) >= 1),
        'has_emotion': int(any(w in text_low for w in ['—Ä–∞–¥–æ—Å—Ç–Ω—ã–π', '—Å—á–∞—Å—Ç–ª–∏–≤', '—É–ª—ã–±–∞–µ—Ç—Å—è', '–≤–µ—Å–µ–ª–æ'])),
        'is_garbage': int(any(w in text_low for w in [
            'characterization', 'leather.ru', 'Feit', '–ü–∞—Å–ø–æ—Ä—Ç–Ω—ã–π –∫–∞–Ω–∞–ª', 'understanding'
        ]) or len(text.split()) < 3)
    }

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ ===
def grade_exam(uploaded_file):
    try:
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        df = pd.read_csv(uploaded_file, sep=';', on_bad_lines='skip')

        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
        progress_bar = st.progress(0)
        status_text = st.empty()

        status_text.text("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ...")
        progress_bar.progress(10)

        if '–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞' in df.columns:
            df = df.drop(columns=['–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞'])

        required_cols = ['Id —ç–∫–∑–∞–º–µ–Ω–∞', 'Id –≤–æ–ø—Ä–æ—Å–∞', '‚Ññ –≤–æ–ø—Ä–æ—Å–∞', '–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞',
                         '–ö–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞', '–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞', '–°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∑–∞–ø–∏—Å']
        for col in required_cols:
            if col not in df.columns:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞: {col}")

        status_text.text("üßπ –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç...")
        progress_bar.progress(30)

        df['–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞_clean'] = df['–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞'].apply(clean_html)
        df['cleaned_transcript'] = df.apply(
            lambda row: remove_instruction(row['–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞'], row['‚Ññ –≤–æ–ø—Ä–æ—Å–∞']),
            axis=1
        )
        df['combined_text'] = df['–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞_clean'] + ' [SEP] ' + df['cleaned_transcript'].fillna('')

        status_text.text("üìä –í—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫–∏...")
        progress_bar.progress(60)

        y_pred = np.zeros(len(df), dtype=int)

        for q_num in [1, 2, 3, 4]:
            mask = df['‚Ññ –≤–æ–ø—Ä–æ—Å–∞'] == q_num
            if not mask.any():
                continue

            if q_num == 4:
                X_text = tfidf_q4.transform(df.loc[mask, 'combined_text'])
                ling_feat = np.array([extract_features(txt) for txt in df.loc[mask, 'cleaned_transcript'].fillna('')])
                ling_scaled = scaler_q4.transform(ling_feat)
                feats = df.loc[mask, 'cleaned_transcript'].apply(get_q4_features_enhanced)
                feature_cols = list(feats.iloc[0].keys())
                checklist_feat = np.array([list(f.values()) for f in feats])
                X = hstack([X_text, csr_matrix(ling_scaled), csr_matrix(checklist_feat)])
                pred_raw = model_q4.predict(X)
                pred_rounded = np.array([int(np.clip(round(p), 0, 2)) for p in pred_raw])
                pred_rounded[checklist_feat[:, -1] == 1] = 0
                y_pred[mask] = pred_rounded
            else:
                X_text = tfidf.transform(df.loc[mask, 'combined_text'])
                ling_feat = np.array([extract_features(txt) for txt in df.loc[mask, 'cleaned_transcript'].fillna('')])
                ling_scaled = scaler.transform(ling_feat)
                q_norm = np.full((mask.sum(), 1), q_num / 4.0)
                X = hstack([X_text, csr_matrix(q_norm), csr_matrix(ling_scaled)])
                model = {1: model_q1, 2: model_q2, 3: model_q3}[q_num]
                pred_raw = model.predict(X)
                if q_num in (1, 3):
                    pred_rounded = np.array([0 if p < 0.5 else 1 for p in pred_raw])
                else:
                    pred_rounded = np.array([int(np.clip(round(p), 0, 2)) for p in pred_raw])
                y_pred[mask] = pred_rounded

        df['–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞'] = y_pred
        output_cols = ['Id —ç–∫–∑–∞–º–µ–Ω–∞', 'Id –≤–æ–ø—Ä–æ—Å–∞', '‚Ññ –≤–æ–ø—Ä–æ—Å–∞', '–¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞',
                       '–ö–∞—Ä—Ç–∏–Ω–∫–∞ –∏–∑ –≤–æ–ø—Ä–æ—Å–∞', '–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞',
                       '–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞', '–°—Å—ã–ª–∫–∞ –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –∑–∞–ø–∏—Å']
        df = df[output_cols]

        status_text.text("‚úÖ –ì–æ—Ç–æ–≤–æ!")
        progress_bar.progress(100)

        return df

    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        return None

# === –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∑–∞–≥—Ä—É–∑–∫–∏ ===
st.header("üìÅ –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")

uploaded_file = st.file_uploader(
    "–í—ã–±–µ—Ä–∏ CSV —Ñ–∞–π–ª —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'",
    type=['csv'],
    help="–§–∞–π–ª –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏: Id —ç–∫–∑–∞–º–µ–Ω–∞, Id –≤–æ–ø—Ä–æ—Å–∞, ‚Ññ –≤–æ–ø—Ä–æ—Å–∞, –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞, –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –∏ –¥—Ä."
)

if uploaded_file is not None:
    st.success(f"‚úÖ –§–∞–π–ª –∑–∞–≥—Ä—É–∂–µ–Ω: {uploaded_file.name}")

    if st.button("üöÄ –ù–∞—á–∞—Ç—å –æ—Ü–µ–Ω–∫—É", type="primary"):
        with st.spinner('–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ...'):
            result_df = grade_exam(uploaded_file)

        if result_df is not None:
            st.success("–û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            st.subheader("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ü–µ–Ω–æ–∫")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("–í—Å–µ–≥–æ –æ—Ç–≤–µ—Ç–æ–≤", len(result_df))
            with col2:
                st.metric("–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞", f"{result_df['–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞'].mean():.2f}")
            with col3:
                st.metric("–ú–∞–∫—Å –æ—Ü–µ–Ω–∫–∞", result_df['–û—Ü–µ–Ω–∫–∞ —ç–∫–∑–∞–º–µ–Ω–∞—Ç–æ—Ä–∞'].max())

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            st.dataframe(result_df.head(10))

            # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            st.subheader("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
            csv = result_df.to_csv(index=False, sep=';')
            st.download_button(
                label="–°–∫–∞—á–∞—Ç—å CSV —Å –æ—Ü–µ–Ω–∫–∞–º–∏",
                data=csv,
                file_name="graded_exam_results.csv",
                mime="text/csv"
            )

st.info("üí°‚Ä¢ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –≤ —Ñ–æ—Ä–º–∞—Ç–µ CSV —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º ';'")
